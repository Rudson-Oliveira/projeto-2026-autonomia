# üöÄ N8N Workflow Template: Auto-Healing para Or√ßamentos

Este template de workflow n8n foi projetado para aumentar a resili√™ncia do processamento de or√ßamentos, incorporando mecanismos de tratamento de erros (Try/Catch) e retentativas autom√°ticas. Ele garante que falhas tempor√°rias na comunica√ß√£o com o Ollama ou outros servi√ßos n√£o interrompam o fluxo de trabalho, minimizando a interven√ß√£o humana.

## üí° Funcionalidades:
- **Tratamento de Erros:** Captura exce√ß√µes em n√≥s cr√≠ticos (ex: requisi√ß√µes HTTP para o Ollama).
- **Retentativas Autom√°ticas:** Tenta novamente a opera√ß√£o ap√≥s um breve intervalo em caso de falha.
- **Notifica√ß√£o de Falha:** Envia alertas para o Hub Central (ou outro canal configurado) em caso de falha persistente.
- **Fallback:** Possibilidade de implementar l√≥gica de fallback (ex: usar um modelo Ollama diferente ou um LLM de nuvem).

## üõ†Ô∏è Como Usar:
1.  **Baixe o JSON:** Copie o conte√∫do JSON abaixo.
2.  **Importe no n8n:** No seu n8n local, v√° em `Workflows` -> `New` -> `Import from JSON`.
3.  **Configure:** Ajuste os n√≥s de requisi√ß√£o HTTP para apontar para o seu Ollama local (`http://localhost:11434/api/generate`).
4.  **Ative:** Publique o workflow.

## üìÑ JSON do Workflow (Exemplo Simplificado):

```json
{
  "nodes": [
    {
      "parameters": {},
      "name": "Start",
      "type": "n8n-nodes-base.start",
      "typeVersion": 1,
      "id": "b1c2d3e4-f5a6-7890-1234-567890abcdef",
      "startNode": true,
      "position": [240, 300]
    },
    {
      "parameters": {
        "mode": "runOnce",
        "options": {}
      },
      "name": "Try_Ollama_Request",
      "type": "n8n-nodes-base.tryCatch",
      "typeVersion": 1,
      "position": [440, 300]
    },
    {
      "parameters": {
        "url": "http://localhost:11434/api/generate",
        "method": "POST",
        "bodyParameters": [
          {
            "name": "model",
            "value": "phi3"
          },
          {
            "name": "prompt",
            "value": "Extraia o valor total e os itens deste or√ßamento: {{ $json.orcamento }}"
          },
          {
            "name": "stream",
            "value": false
          }
        ],
        "options": {
          "retryOnFail": true,
          "retryInterval": 10000,
          "retryAttempts": 3
        }
      },
      "name": "HTTP_Request_Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 3,
      "position": [640, 200]
    },
    {
      "parameters": {
        "content": "Falha na extra√ß√£o do or√ßamento: {{ $json.orcamento }}. Erro: {{ $json.error }}",
        "options": {}
      },
      "name": "Notify_Failure",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [640, 400]
    },
    {
      "parameters": {
        "value": "{{ $json.data }}",
        "options": {}
      },
      "name": "Process_Success",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [840, 200]
    }
  ],
  "connections": {
    "Start": [
      [
        {
          "node": "Try_Ollama_Request",
          "type": "main",
          "index": 0
        }
      ]
    ],
    "Try_Ollama_Request": [
      [
        {
          "node": "HTTP_Request_Ollama",
          "type": "main",
          "index": 0
        }
      ],
      [
        {
          "node": "Notify_Failure",
          "type": "main",
          "index": 0
        }
      ]
    ],
    "HTTP_Request_Ollama": [
      [
        {
          "node": "Process_Success",
          "type": "main",
          "index": 0
        }
      ]
    ]
  }
}
```

## ‚öôÔ∏è Otimiza√ß√£o de Mem√≥ria para Ollama (Docker)

Para evitar que o Ollama trave devido √† falta de mem√≥ria, √© crucial alocar recursos adequados ao container Docker. Recomenda-se um m√≠nimo de 8GB de RAM para modelos como o `phi3`.

### üìù Instru√ß√µes:
1.  **Abra o Docker Desktop:** V√° para `Settings` (Configura√ß√µes) -> `Resources` (Recursos) -> `Advanced` (Avan√ßado).
2.  **Ajuste a Mem√≥ria:** Aumente o limite de mem√≥ria para **8GB ou mais**.
3.  **Aplique e Reinicie:** Clique em `Apply & Restart`.

Esta configura√ß√£o garantir√° que o Ollama tenha mem√≥ria suficiente para carregar e processar os modelos sem interrup√ß√µes.
